삼성증권은 보안 상 이유로 로그인이 필요한 사이트이므로, 로그인 정보를 알고 있어야 크롤링을 할 수 있습니다. 또한, 삼성증권에서 제공하는 주식 일별 시세 정보는 다음과 같은 URL 패턴을 가지고 있습니다.

bash
Copy code
https://www.samsungpop.com/sub.html?cont=/investor/popup_stock/stock_day_price&type=1&code={stock_code}
여기서 {stock_code} 부분은 각 종목마다 고유한 종목 코드로 대체됩니다. 예를 들어 삼성전자의 종목 코드는 005930 입니다. 이를 이용하여 각 종목별 일별 시세 정보를 크롤링할 수 있습니다.

따라서, 삼성증권에 로그인한 후, 일별 시세 정보를 가져오는 과정을 반복적으로 수행하여 원하는 종목들의 일별 시세 정보를 크롤링하는 코드를 작성할 수 있습니다. 다음은 예시 코드입니다.

python
Copy code
import requests
from bs4 import BeautifulSoup

# 로그인 정보
login_info = {
    'userId': 'your_id',
    'userPwd': 'your_password'
}

# 종목 코드 리스트
stock_codes = ['005930', '000660', '035720']

# 세션 생성
session = requests.Session()

# 로그인 페이지 가져오기
login_page = session.get('https://www.samsungpop.com/login/sso.jsp')

# 로그인 폼 파싱하기
soup = BeautifulSoup(login_page.text, 'html.parser')
login_form = soup.find('form')

# 로그인 폼에 포함된 input 요소 파싱하기
inputs = login_form.findAll('input')

# input 요소에서 로그인 정보에 맞게 입력할 데이터 추출하기
login_data = { i.get('name'): i.get('value') for i in inputs }

# 로그인 정보 추가하기
login_data.update(login_info)

# 로그인 시도
session.post('https://www.samsungpop.com/login/sso.jsp', data=login_data)

# 종목별로 일별 시세 정보 크롤링하기
for stock_code in stock_codes:
    # 종목별 일별 시세 정보 페이지 가져오기
    stock_page = session.get(f'https://www.samsungpop.com/sub.html?cont=/investor/popup_stock/stock_day_price&type=1&code={stock_code}')

    # 일별 시세 정보 파싱하기
    soup = BeautifulSoup(stock_page.text, 'html.parser')
    table = soup.find('table')
    rows = table.findAll('tr')

    # 일별 시세 정보 출력하기
    for row in rows:
        cols = row.findAll('td')
        if len(cols) == 7:
            date = cols[0].text.strip()
            price = cols[1].text.strip()
            print(f'{date}, {price}, {stock_code}')
위 코드에서는 먼저 로그인 정보와 종목 코드 리스트를 설정합니다. 그리고 requests.Session 객체를 생성하여 삼성증권에 로그인


로그인 폼에 접근하여 BeautifulSoup 라이브러리를 사용하여 파싱합니다. 이 때, 로그인 폼의 form 요소와 그 하위에 있는 input 요소들을 추출합니다.

로그인 폼의 input 요소에서 추출한 정보와 로그인 정보를 합쳐서 로그인을 시도합니다. requests.Session 객체를 사용하여 로그인한 후, 
각 종목별 일별 시세 정보 페이지에 접근하여, 원하는 정보를 크롤링합니다.

이때, 종목별 일별 시세 정보 페이지의 URL은 종목 코드를 사용하여 생성하며, BeautifulSoup 라이브러리를 사용하여 해당 페이지의 HTML을 파싱합니다. 
그리고 table 요소와 tr 요소를 사용하여 일별 시세 정보를 추출합니다.

마지막으로, 추출한 일별 시세 정보를 출력합니다. 위 코드에서는 각 종목마다의 일별 시세 정보를 출력하지만, 이를 파일로 저장하는 등의 추가 작업을
 수행하여 원하는 방식으로 활용할 수 있습니다.


