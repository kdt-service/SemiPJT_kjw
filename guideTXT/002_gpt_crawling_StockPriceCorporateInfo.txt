만약, 대상사이트에서 일자별 주식종목의 가격뿐만 아니라 PER, PBR, ROE, 순이익, 영업이익같은 기업정보도 크롤링하려고 하면 어떻게 해야 할까요? 추가해야할 코딩을 보여주시기 바랍니다.
일별 시세 정보 페이지 외에 기업 정보를 크롤링하기 위해서는, 기업 정보 페이지를 파싱하여 원하는 정보를 추출해야 합니다. 삼성증권에서 제공하는 기업 정보 페이지는 다음과 같은 URL 패턴을 가지고 있습니다.

bash
Copy code
https://www.samsungpop.com/sub.html?cont=/investor/stock_guide/invest_guide_01&type=2&code={stock_code}
여기서 {stock_code} 부분은 각 종목마다 고유한 종목 코드로 대체됩니다. 이를 이용하여 각 종목별 기업 정보를 크롤링할 수 있습니다.

따라서, 로그인 후 각 종목별 일별 시세 정보와 기업 정보를 가져오는 과정을 반복적으로 수행하여 원하는 종목들의 일별 시세 정보와 기업 정보를 크롤링하는 코드를 작성할 수 있습니다. 다음은 예시 코드입니다.

python
Copy code
import requests
from bs4 import BeautifulSoup

# 로그인 정보
login_info = {
    'userId': 'your_id',
    'userPwd': 'your_password'
}

# 종목 코드 리스트
stock_codes = ['005930', '000660', '035720']

# 세션 생성
session = requests.Session()

# 로그인 페이지 가져오기
login_page = session.get('https://www.samsungpop.com/login/sso.jsp')

# 로그인 폼 파싱하기
soup = BeautifulSoup(login_page.text, 'html.parser')
login_form = soup.find('form')

# 로그인 폼에 포함된 input 요소 파싱하기
inputs = login_form.findAll('input')

# input 요소에서 로그인 정보에 맞게 입력할 데이터 추출하기
login_data = { i.get('name'): i.get('value') for i in inputs }

# 로그인 정보 추가하기
login_data.update(login_info)

# 로그인 시도
session.post('https://www.samsungpop.com/login/sso.jsp', data=login_data)

# 종목별로 일별 시세 정보와 기업 정보 크롤링하기
for stock_code in stock_codes:
    # 종목별 일별 시세 정보 페이지 가져오기
    stock_page = session.get(f'https://www.samsungpop.com/sub.html?cont=/investor/popup_stock/stock_day_price&type=1&code={stock_code}')

    # 일별 시세 정보 파싱하기
    soup = BeautifulSoup(stock_page.text, 'html.parser')
    table = soup.find('table')
    rows = table.findAll('tr')

    # 일별 시세 정보 출력하기
    for row in rows:
        cols = row.findAll('td')
        if len(cols) == 7:
            date = cols[0].text.strip()
            price = cols[1].text.strip()
            print(f'{date}, {price}, {stock_code}')

    # 종목별 기업 정보 페이지 가져오기
    company_page = session.get(f'https://www.samsungpop.com/sub.html?cont=/investor/stock_guide/invest_guide_01&type=2&code={stock_code}')

    # 기업 정보 파싱하기
    soup = BeautifulSoup(company_page.text, 'html.parser')
    table




JW Kim
# 기업 정보 파싱하기  이후의 코딩만 계속 보여주십시오.
위 코드에서 기업 정보 페이지를 파싱한 후에는, table 요소와 tr 요소, 그리고 th 요소를 사용하여 기업 정보를 추출할 수 있습니다.

따라서, 아래와 같이 각 종목별 기업 정보를 크롤링하고 출력하는 코드를 추가할 수 있습니다.

python
Copy code
    # 기업 정보 파싱하기
    soup = BeautifulSoup(company_page.text, 'html.parser')
    table = soup.find('table')

    # 기업 정보 추출하기
    company_info = {}
    for tr in table.findAll('tr'):
        th = tr.find('th')
        td = tr.find('td')
        if th and td:
            key = th.text.strip().replace(' ', '_')
            value = td.text.strip()
            company_info[key] = value

    # 기업 정보 출력하기
    print(f'종목 코드: {stock_code}')
    for key, value in company_info.items():
        print(f'{key}: {value}')
위 코드에서는 기업 정보 페이지에서 table 요소를 추출하고, for 루프를 사용하여 tr 요소와 th 요소, 그리고 td 요소를 차례로 추출합니다.

th 요소에서는 기업 정보의 항목명을 추출하고, td 요소에서는 해당 항목의 값을 추출합니다. 추출한 항목명과 값은 딕셔너리 객체 company_info에 저장됩니다.

마지막으로, for 루프를 사용하여 company_info 딕셔너리의 항목들을 출력합니다. 이를 위해서는 각 항목의 이름을 적절하게 변환하여 출력해야 합니다. 
위 코드에서는 항목명의 공백을 언더바(_)로 대체하였습니다.